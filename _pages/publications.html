---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}

<!-- <h2>Under Review</h2>
<ul>
  <li>
    <strong>LES-Talker: Fine-Grained Emotion Editing in Linear Emotion Space</strong><br>
    <em>First Author</em><br>
    Under Review at ICCV 2025<br>
    <ul>
      <li>Led the full research pipeline, from problem formulation to model design, experimentation, and paper writing</li>
      <li>Proposed the Linear Emotion Space (LES), a novel interpretable framework enabling fine-grained emotion editing across types, intensities, and facial units</li>
      <li>Designed LES-Talker with a universal Cross-Dimension Attention Network to align 3D model deformation with emotional control signals, achieving high-quality and controllable talking head generation</li>
    </ul>
  </li>
  <li>
    <strong>EmoSpeaker: Emotion-Controlled Talking Face Generation</strong><br>
    <em>Co-author</em><br>
    Under Review at IEEE TMM<br>
    <ul>
      <li>Assisted in a one-shot framework capable of fine-grained emotional control and precise lip synchronization</li>
      <li>Contributed to the design of an audio decoupling mechanism guided by facial attributes</li>
      <li>Actively involved in paper revision and rebuttal writing, focusing on technical clarity, reviewer responses, and refinement of contributions</li>
    </ul>
  </li>
</ul>

<h2>Accepted</h2>
<ul>
  <li>
    <strong>KAN-Face: Efficient Resource Usage and Precision Lip-Sync</strong><br>
    <em>Co-author</em><br>
    Accepted at ICASSP 2025<br>
    <ul>
      <li>Contributed to the design and refinement of a lightweight framework utilizing KANs for efficient and accurate talking head generation</li>
      <li>Participated in the development and review of the Lip-Sync Enhancement Module, which integrates audio-temporal features and 3D representations to improve sync precision</li>
      <li>Actively involved in technical discussions and rebuttal preparation, focusing on highlighting contributions and addressing reviewer feedback</li>
    </ul>
  </li>
</ul> -->



